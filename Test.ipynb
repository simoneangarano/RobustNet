{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "DATASET = 'gtav' # 'synthia' or 'gtav'\n",
    "I_ROOT = '/home/simone/Datasets/Synthia/RGB' if DATASET == 'synthia' else '/home/simone/Datasets/GTAV/images' \n",
    "L_ROOT = '/home/simone/Datasets/Synthia/GT/LABELS' if DATASET == 'synthia' else '/home/simone/Datasets/GTAV/labels'\n",
    "Z = 7 if DATASET == 'synthia' else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "train_ids = [line.strip() for line in lines]\n",
    "print(len(train_ids))\n",
    "\n",
    "with open('val.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "val_ids = [line.strip() for line in lines]\n",
    "print(len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in train_ids:\n",
    "    shutil.copy(f\"{I_ROOT}/{id.zfill(Z)}.png\", f\"{I_ROOT}/train/{id.zfill(Z)}.png\")\n",
    "    shutil.copy(f\"{L_ROOT}/{id.zfill(Z)}.png\", f\"{L_ROOT}/train/{id.zfill(Z)}.png\")\n",
    "\n",
    "for id in val_ids:\n",
    "    shutil.copy(f\"{I_ROOT}/{id.zfill(Z)}.png\", f\"{I_ROOT}/val/{id.zfill(Z)}.png\")\n",
    "    shutil.copy(f\"{L_ROOT}/{id.zfill(Z)}.png\", f\"{L_ROOT}/val/{id.zfill(Z)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DomainMix, CopyPaste, and CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = imageio.imread(f\"../../Datasets/Synthia/GT/LABELS/train/0000000.png\")\n",
    "l = imageio.imread(f\"../../Datasets/Synthia/GT/LABELS/train/0000000.png\", format='PNG-FI')\n",
    "# l = imageio.v3.imread(f\"../../Datasets/Synthia/GT/LABELS/train/0000000.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(l[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(l[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.synthia import Synthia\n",
    "\n",
    "train_set = Synthia(\n",
    "    'train', 0,\n",
    "    joint_transform=None,\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    "    target_aux_transform=None,\n",
    "    dump_images=False,\n",
    "    cv_split=False,\n",
    "    image_in=False, \n",
    "    max_iters=2975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from config import cfg, assert_and_infer_cfg\n",
    "from utils.misc import prep_experiment\n",
    "import datasets\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Semantic Segmentation')\n",
    "    parser.add_argument('--lr', type=float, default=0.01)\n",
    "    parser.add_argument('--arch', type=str, default='network.deepv3.DeepWV3Plus',\n",
    "                        help='Network architecture. We have DeepSRNX50V3PlusD (backbone: ResNeXt50) \\\n",
    "                        and deepWV3Plus (backbone: WideResNet38).')\n",
    "    parser.add_argument('--dataset', nargs='*', type=str, default=['cityscapes'],\n",
    "                        help='a list of datasets; cityscapes, mapillary, camvid, kitti, gtav, mapillary, synthia')\n",
    "    parser.add_argument('--image_uniform_sampling', action='store_true', default=False,\n",
    "                        help='uniformly sample images across the multiple source domains')\n",
    "    parser.add_argument('--val_dataset', nargs='*', type=str, default=['bdd100k'],\n",
    "                        help='a list consists of cityscapes, mapillary, gtav, bdd100k, synthia')\n",
    "    parser.add_argument('--covstat_val_dataset', nargs='*', type=str, default=[],\n",
    "                        help='a list consists of cityscapes, mapillary, gtav, bdd100k, synthia')\n",
    "    parser.add_argument('--cv', type=int, default=0,\n",
    "                        help='cross-validation split id to use. Default # of splits set to 3 in config')\n",
    "    parser.add_argument('--class_uniform_pct', type=float, default=0,\n",
    "                        help='What fraction of images is uniformly sampled')\n",
    "    parser.add_argument('--class_uniform_tile', type=int, default=1024,\n",
    "                        help='tile size for class uniform sampling')\n",
    "    parser.add_argument('--coarse_boost_classes', type=str, default=None,\n",
    "                        help='use coarse annotations to boost fine data with specific classes')\n",
    "\n",
    "    parser.add_argument('--img_wt_loss', action='store_true', default=False,\n",
    "                        help='per-image class-weighted loss')\n",
    "    parser.add_argument('--cls_wt_loss', action='store_true', default=False,\n",
    "                        help='class-weighted loss')\n",
    "    parser.add_argument('--batch_weighting', action='store_true', default=False,\n",
    "                        help='Batch weighting for class (use nll class weighting using batch stats')\n",
    "\n",
    "    parser.add_argument('--jointwtborder', action='store_true', default=False,\n",
    "                        help='Enable boundary label relaxation')\n",
    "    parser.add_argument('--strict_bdr_cls', type=str, default='',\n",
    "                        help='Enable boundary label relaxation for specific classes')\n",
    "    parser.add_argument('--rlx_off_iter', type=int, default=-1,\n",
    "                        help='Turn off border relaxation after specific epoch count')\n",
    "    parser.add_argument('--rescale', type=float, default=1.0,\n",
    "                        help='Warm Restarts new learning rate ratio compared to original lr')\n",
    "    parser.add_argument('--repoly', type=float, default=1.5,\n",
    "                        help='Warm Restart new poly exp')\n",
    "\n",
    "    parser.add_argument('--fp16', action='store_true', default=False,\n",
    "                        help='Use Nvidia Apex AMP')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='parameter used by apex library')\n",
    "\n",
    "    parser.add_argument('--sgd', action='store_true', default=True)\n",
    "    parser.add_argument('--adam', action='store_true', default=False)\n",
    "    parser.add_argument('--amsgrad', action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument('--freeze_trunk', action='store_true', default=False)\n",
    "    parser.add_argument('--hardnm', default=0, type=int,\n",
    "                        help='0 means no aug, 1 means hard negative mining iter 1,' +\n",
    "                        '2 means hard negative mining iter 2')\n",
    "\n",
    "    parser.add_argument('--trunk', type=str, default='resnet101',\n",
    "                        help='trunk model, can be: resnet101 (default), resnet50')\n",
    "    parser.add_argument('--max_epoch', type=int, default=180)\n",
    "    parser.add_argument('--max_iter', type=int, default=30000)\n",
    "    parser.add_argument('--max_cu_epoch', type=int, default=100000,\n",
    "                        help='Class Uniform Max Epochs')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0)\n",
    "    parser.add_argument('--crop_nopad', action='store_true', default=False)\n",
    "    parser.add_argument('--rrotate', type=int,\n",
    "                        default=0, help='degree of random roate')\n",
    "    parser.add_argument('--color_aug', type=float,\n",
    "                        default=0.0, help='level of color augmentation')\n",
    "    parser.add_argument('--gblur', action='store_true', default=False,\n",
    "                        help='Use Guassian Blur Augmentation')\n",
    "    parser.add_argument('--bblur', action='store_true', default=False,\n",
    "                        help='Use Bilateral Blur Augmentation')\n",
    "    parser.add_argument('--lr_schedule', type=str, default='poly',\n",
    "                        help='name of lr schedule: poly')\n",
    "    parser.add_argument('--poly_exp', type=float, default=0.9,\n",
    "                        help='polynomial LR exponent')\n",
    "    parser.add_argument('--bs_mult', type=int, default=2,\n",
    "                        help='Batch size for training per gpu')\n",
    "    parser.add_argument('--bs_mult_val', type=int, default=1,\n",
    "                        help='Batch size for Validation per gpu')\n",
    "    parser.add_argument('--crop_size', type=int, default=720,\n",
    "                        help='training crop size')\n",
    "    parser.add_argument('--pre_size', type=int, default=None,\n",
    "                        help='resize image shorter edge to this before augmentation')\n",
    "    parser.add_argument('--scale_min', type=float, default=0.5,\n",
    "                        help='dynamically scale training images down to this size')\n",
    "    parser.add_argument('--scale_max', type=float, default=2.0,\n",
    "                        help='dynamically scale training images up to this size')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4)\n",
    "    parser.add_argument('--momentum', type=float, default=0.9)\n",
    "    parser.add_argument('--snapshot', type=str, default=None)\n",
    "    parser.add_argument('--restore_optimizer', action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument('--city_mode', type=str, default='train',\n",
    "                        help='experiment directory date name')\n",
    "    parser.add_argument('--date', type=str, default='default',\n",
    "                        help='experiment directory date name')\n",
    "    parser.add_argument('--exp', type=str, default='default',\n",
    "                        help='experiment directory name')\n",
    "    parser.add_argument('--tb_tag', type=str, default='',\n",
    "                        help='add tag to tb dir')\n",
    "    parser.add_argument('--ckpt', type=str, default='logs/ckpt',\n",
    "                        help='Save Checkpoint Point')\n",
    "    parser.add_argument('--tb_path', type=str, default='logs/tb',\n",
    "                        help='Save Tensorboard Path')\n",
    "    parser.add_argument('--syncbn', action='store_true', default=False,\n",
    "                        help='Use Synchronized BN')\n",
    "    parser.add_argument('--dump_augmentation_images', action='store_true', default=False,\n",
    "                        help='Dump Augmentated Images for sanity check')\n",
    "    parser.add_argument('--test_mode', action='store_true', default=False,\n",
    "                        help='Minimum testing to verify nothing failed, ' +\n",
    "                        'Runs code for 1 epoch of train and val')\n",
    "    parser.add_argument('-wb', '--wt_bound', type=float, default=1.0,\n",
    "                        help='Weight Scaling for the losses')\n",
    "    parser.add_argument('--maxSkip', type=int, default=0,\n",
    "                        help='Skip x number of  frames of video augmented dataset')\n",
    "    parser.add_argument('--scf', action='store_true', default=False,\n",
    "                        help='scale correction factor')\n",
    "    parser.add_argument('--dist_url', default='tcp://127.0.0.1:', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "\n",
    "    parser.add_argument('--wt_layer', nargs='*', type=int, default=[0,0,0,0,0,0,0],\n",
    "                        help='0: None, 1: IW/IRW, 2: ISW, 3: IS, 4: IN (IBNNet: 0 0 4 4 4 0 0)')\n",
    "    parser.add_argument('--wt_reg_weight', type=float, default=0.0)\n",
    "    parser.add_argument('--relax_denom', type=float, default=2.0)\n",
    "    parser.add_argument('--clusters', type=int, default=50)\n",
    "    parser.add_argument('--trials', type=int, default=10)\n",
    "    parser.add_argument('--dynamic', action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument('--image_in', action='store_true', default=False,\n",
    "                        help='Input Image Instance Norm')\n",
    "    parser.add_argument('--cov_stat_epoch', type=int, default=5,\n",
    "                        help='cov_stat_epoch')\n",
    "    parser.add_argument('--visualize_feature', action='store_true', default=False,\n",
    "                        help='Visualize intermediate feature')\n",
    "    parser.add_argument('--use_wtloss', action='store_true', default=False,\n",
    "                        help='Automatic setting from wt_layer')\n",
    "    parser.add_argument('--use_isw', action='store_true', default=False,\n",
    "                        help='Automatic setting from wt_layer')\n",
    "\n",
    "    parser.add_argument('--kd', action='store_true', default=False)\n",
    "    parser.add_argument('--weights_dir', type=str, default='./bin/')\n",
    "    parser.add_argument('--return_list', action='store_true', default=False)\n",
    "    parser.add_argument('--reproduce', action='store_true', default=False)\n",
    "\n",
    "    return parser\n",
    "\n",
    "def init():\n",
    "    parser = parse_args()\n",
    "    args = parser.parse_args([\"--dataset\", DATASET, # \"gtav\", \"bdd100k\", \"cityscapes\", \"mapillary\", \"synthia\",\n",
    "                            \"--val_dataset\", DATASET, # \"gtav\", \"bdd100k\", \"cityscapes\", \"mapillary\", \"synthia\",\n",
    "                            \"--arch\", \"network.deepv3.DeepR50V3PlusD\", \"--city_mode\", \"train\", \"--sgd\", \"--lr_schedule\", \"poly\", \n",
    "                            \"--lr\", \"0.01\", \"--poly_exp\", \"0.9\", \"--max_cu_epoch\", \"10000\", \"--class_uniform_pct\", \"0.0\", \n",
    "                            \"--class_uniform_tile\", \"512\", \"--crop_size\", \"768\", \"--scale_min\", \"0.5\", \"--scale_max\", \"2.0\", \n",
    "                            \"--rrotate\", \"0\", \"--max_iter\", \"40000\", \"--bs_mult\", \"8\", \"--gblur\", \"--color_aug\", \"0.5\", \n",
    "                            \"--date\", \"0101\", \"--exp\", \"test\", \"--ckpt\", \"./logs/\", \"--tb_path\", \"./logs/\", \"--wt_reg_weight\", \"0.0\",\n",
    "                            \"--relax_denom\", \"0.0\", \"--cov_stat_epoch\", \"0\", \"--wt_layer\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\"])\n",
    "\n",
    "    # Enable CUDNN Benchmarking optimization\n",
    "    if args.reproduce:\n",
    "        random_seed = cfg.RANDOM_SEED  #304\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "    else:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    args.world_size = 1\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "\n",
    "    for i in range(len(args.wt_layer)):\n",
    "        if args.wt_layer[i] == 1:\n",
    "            args.use_wtloss = True\n",
    "        if args.wt_layer[i] == 2:\n",
    "            args.use_wtloss = True\n",
    "            args.use_isw = True\n",
    "    return args, parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'gtav' # 'synthia' or 'gtav'\n",
    "args, parser = init()\n",
    "assert_and_infer_cfg(args)\n",
    "writer = prep_experiment(args, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, val_list, name = datasets.setup_loaders(args)\n",
    "len(train_list[0]), len(val_list[0]), name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "gtav_to_cityscapes = {\n",
    "    7: 0,\n",
    "    8: 1, \n",
    "    11: 2, \n",
    "    12: 3, \n",
    "    13: 4, \n",
    "    17: 5,\n",
    "    19: 6, \n",
    "    20: 7, \n",
    "    21: 8, \n",
    "    22: 9, \n",
    "    23: 10, \n",
    "    24: 11, \n",
    "    25: 12,\n",
    "    26: 13, \n",
    "    27: 14, \n",
    "    28: 15, \n",
    "    31: 16, \n",
    "    32: 17, \n",
    "    33: 18\n",
    "    }\n",
    "\n",
    "synthia_to_cityscapes = {\n",
    "    0: 255,  # void\n",
    "    1: 10,   # sky\n",
    "    2: 2,    # building\n",
    "    3: 0,    # road\n",
    "    4: 1,    # sidewalk\n",
    "    5: 4,    # fence\n",
    "    6: 8,    # vegetation\n",
    "    7: 5,    # pole\n",
    "    8: 13,   # car\n",
    "    9: 7,    # traffic sign\n",
    "    10: 11,  # pedestrian - person\n",
    "    11: 18,  # bicycle\n",
    "    12: 17,  # motorcycle\n",
    "    13: 255, # parking-slot\n",
    "    14: 255, # road-work\n",
    "    15: 6,   # traffic light\n",
    "    16: 9,   # terrain\n",
    "    17: 12,  # rider\n",
    "    18: 14,  # truck\n",
    "    19: 15,  # bus\n",
    "    20: 16,  # train\n",
    "    21: 3,   # wall\n",
    "    22: 255  # Lanemarking\n",
    "    }\n",
    "\n",
    "def get_classes(lst, dct, fnc):\n",
    "    cls_old, cls_new = set(), set()\n",
    "    for _, lp in lst:\n",
    "        l = np.array(fnc(lp))\n",
    "        l = l[...,0] if len(l.shape) == 3 else l\n",
    "        cls_old.update(l.flatten())\n",
    "\n",
    "        lc = np.full(l.shape, 255, dtype=np.uint8)\n",
    "        for k, v in dct.items():\n",
    "            lc[l == k] = v\n",
    "        cls_new.update(lc.flatten())\n",
    "    return cls_old, cls_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = gtav_to_cityscapes if args.dataset == ['gtav'] else synthia_to_cityscapes if args.dataset == ['synthia'] else {}\n",
    "fnc = imageio.v3.imread if args.dataset == ['gtav'] else lambda f: imageio.v2.imread(f,format='PNG-FI') if args.dataset == ['synthia'] else None\n",
    "print(get_classes(val_list[0], dct, fnc))\n",
    "# print(get_classes(train_list[0], dct, fnc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loaders, train_obj, extra_val_loaders, covstat_val_loaders = datasets.setup_loaders(args)\n",
    "len(train_loader), len(val_loaders[DATASET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = set()\n",
    "for i, (img, lbl, _, _) in enumerate(val_loaders[DATASET]):\n",
    "    cls.update(lbl.unique().numpy())\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([torch.Tensor([0])], lr=1e-2, weight_decay=5e-4, momentum=0.9, nesterov=False)\n",
    "lambda1 = lambda iteration: math.pow(1 - iteration / 40000, 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "lrs = []\n",
    "for _ in range(40000):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "plt.plot(lrs)\n",
    "plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "miou = np.array([55.65, 37.89, 59.71, 51.93, 56.20])\n",
    "miou.mean(), miou.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
